# Lab2---Data-Collection-and-Pre-processing
This project involves executing a 12-step data engineering roadmap on an e-commerce dataset. The primary goal is to ingest raw sales data, perform cleaning and enrichment operations, transform the data, and derive a concise analytical insight. This entire process is documented within a well-commented Jupyter Notebook. The project demonstrates common data engineering tasks, object-oriented programming in Python for data handling, and data serialization.

## Quick Start

To set up and run this project locally, follow these steps:

1.  **Clone the repository:**
    ```bash git clone https://github.com/akondeti7046/Lab2---Data-Collection-and-Pre-processing.git ```

2.  **Create and activate a virtual environment:**
    ```bash python -m venv venv source venv/bin/activate ```

3.  **Install dependencies:**
    ```bash pip install -r requirements.txt```


4.  **Run Jupyter Notebook:**
    ```bash jupyter notebook``` 


## Data Source Attribution

* **Primary Transactions File:** The e-commerce sales data was sourced from https://excelbianalytics.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/
* **Secondary Metadata File:** https://www.kaggle.com/datasets/viswanathanc/world-cities-datasets

